{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038c9aeb-9ae0-4501-9089-52ec6449394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wint3rmute/code/baczek.me/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parses all posts as text and creates a \"semantic map\", grouping\n",
    "similar posts together on a 2D plane. Basically:\n",
    "\n",
    "1. Sentence embeddings\n",
    "2. Umap\n",
    "3. Some semi-random links between nodes to make it look smarter than it actually is\n",
    "4. Graphviz to SVG\n",
    "5. Display SVG on the site\n",
    "\n",
    "This notebook also contains some other small utilities used in the site build process,\n",
    "but their importance is negligible therefore I do not document them all.\n",
    "\n",
    "---\n",
    "\n",
    "Notes on the previous version from the preGPT era:\n",
    "\n",
    "Credit: https://flavioclesio.com/cosine-similarity-search-for-new-documents-using-scikit-learn\n",
    "Source SO post: https://stackoverflow.com/questions/44862712/td-idf-find-cosine-similarity-between-new-document-and-dataset/44863365#44863365\n",
    "\n",
    "Disclaimer: I am not a data scientist, just a random guy who wanted to make an automatic\n",
    "\"related posts\" section generator. This script is by no means proffesional\n",
    "nor comprehensive in any way, it's just a quick hack that is good enough for me.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy\n",
    "import subprocess\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "import textwrap\n",
    "\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "\n",
    "import graphviz\n",
    "import umap\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Consider using \"all-MiniLM-L6-v2\" for slightly lower accuracy and 5x performance\n",
    "sentence_transformer = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6585cb2-0f03-419f-a380-e11b497f7239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recently modified:\n",
      "- content/waiting-room.md\n",
      "- content/now.md\n",
      "- content/how-to-think.md\n"
     ]
    }
   ],
   "source": [
    "RECENTLY_MODIFIED_FILES = subprocess.check_output(\n",
    "    \"git log --pretty=format: --name-only | grep '.md' | awk '!seen[$0]++' | head -n 3\",\n",
    "    shell=True,\n",
    ").decode()\n",
    "\n",
    "print(\"Recently modified:\")\n",
    "for line in RECENTLY_MODIFIED_FILES.split(\"\\n\")[\n",
    "    :-1\n",
    "]:  # Last line is empty, skip it with :-1\n",
    "    print(\"-\", line)\n",
    "\n",
    "\n",
    "def was_recently_modified(file_path: Path) -> bool:\n",
    "    for file in RECENTLY_MODIFIED_FILES.split(\"\\n\"):\n",
    "        if str(file_path) in file:\n",
    "            print(file_path, \"was recently modified\")\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_title(file_path: Path, content: str) -> str:\n",
    "    title = None\n",
    "\n",
    "    for line in content.split(\"\\n\"):\n",
    "        if \"title: \" in line:\n",
    "            title = line.replace(\"title: \", \"\").strip()\n",
    "\n",
    "    if not title:\n",
    "        raise ValueError(f\"Title not found in {file_path}\")\n",
    "\n",
    "    return title\n",
    "\n",
    "\n",
    "def extract_tags(file_path: Path, content: str) -> list[str]:\n",
    "    tags = []\n",
    "\n",
    "    for line in content.split(\"\\n\"):\n",
    "        if line.startswith(\"tags: \"):\n",
    "            tags = line.replace(\"tags: \", \"\").split(\",\")\n",
    "            tags = [tag.strip() for tag in tags]\n",
    "\n",
    "    if len(tags) == 0:\n",
    "        warnings.warn(f\"No tags defined for {file_path}\")\n",
    "\n",
    "    return tags\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RelatedPost:\n",
    "    similarity: float\n",
    "    post: \"Post\"\n",
    "    # level: int # 1 = very related, 2 less related, etc\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Post:\n",
    "    title: str\n",
    "    content: str\n",
    "    path: Path\n",
    "    recently_modified: bool\n",
    "\n",
    "    embeddings: numpy.ndarray\n",
    "    tags: list[str] = field(default_factory=list)\n",
    "    related_posts: list[RelatedPost] = field(default_factory=list)\n",
    "\n",
    "    # To be filled by UMAP\n",
    "    _x: float | None = None\n",
    "    _y: float | None = None\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        if self._x is None:\n",
    "            raise ValueError(\"Value of X coordinate not filled\")\n",
    "        return self._x\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        if self._y is None:\n",
    "            raise ValueError(\"Value of Y coordinate not filled\")\n",
    "        return self._y\n",
    "\n",
    "    @property\n",
    "    def link(self) -> str:\n",
    "        post_link = \"/\" + str(\n",
    "            self.path.relative_to(\"content\").parent\n",
    "            / self.path.relative_to(\"content\").stem\n",
    "        )\n",
    "\n",
    "        return post_link\n",
    "\n",
    "    @classmethod\n",
    "    def from_path(cls, path: Path):\n",
    "        if path.suffix == \".md\":\n",
    "            content_raw = path.read_text()\n",
    "            # No easy markdown to text convertsion available at the moment :/\n",
    "            html = markdown.markdown(content_raw)\n",
    "            html_tree = BeautifulSoup(html, features=\"html.parser\")\n",
    "            content = html_tree.text\n",
    "\n",
    "            title = extract_title(path, content_raw)\n",
    "            tags = extract_tags(path, content_raw)\n",
    "\n",
    "        elif path.suffix == \".html\":\n",
    "            content_raw = path.read_text()\n",
    "            html_tree = BeautifulSoup(content_raw, features=\"html.parser\")\n",
    "            html_tree.nav.decompose()\n",
    "            content = html_tree.text.replace(\"\\n\", \"\")\n",
    "            tags = []\n",
    "\n",
    "            title = path.name\n",
    "\n",
    "            to_trim = content.rfind(\"Incoming:\")\n",
    "            if to_trim != -1:\n",
    "                content = content[to_trim:]\n",
    "            # else:\n",
    "            #     print(\"No Incoming\")\n",
    "            #     print(content)\n",
    "\n",
    "        embeddings = sentence_transformer.encode([content])[0]\n",
    "        return cls(\n",
    "            title=title,\n",
    "            content=content,\n",
    "            path=path,\n",
    "            recently_modified=was_recently_modified(path),\n",
    "            tags=tags,\n",
    "            embeddings=embeddings,\n",
    "        )\n",
    "\n",
    "    def __hash__(self) -> None:\n",
    "        return hash(self.path)\n",
    "\n",
    "    def distance_to(self, post: \"Post\") -> float:\n",
    "        return math.sqrt((self.x - post.x) ** 2 + (self.y - post.y) ** 2)\n",
    "        # return -util.cos_sim(self.embeddings, post.embeddings)\n",
    "\n",
    "    def distance_embedding(self, post: \"Post\") -> float:\n",
    "        # return math.sqrt((self.x - post.x) ** 2 + (self.y - post.y) ** 2)\n",
    "        result = -util.cos_sim(self.embeddings, post.embeddings)\n",
    "        return float(result)\n",
    "\n",
    "\n",
    "def get_all_posts() -> list[Post]:\n",
    "    all_posts = []\n",
    "    all_posts_paths = Path.glob(Path(\"./content/\"), \"**/*.md\")\n",
    "\n",
    "    for post_path in all_posts_paths:\n",
    "        all_posts.append(Post.from_path(post_path))\n",
    "\n",
    "    embeddings = [post.embeddings for post in all_posts]\n",
    "\n",
    "    umap_result = umap.UMAP().fit_transform(embeddings)\n",
    "    # umap_result = manifold.TSNE(\n",
    "    #     n_components=2,\n",
    "    #     learning_rate='auto',\n",
    "    #     init='random',\n",
    "    #     perplexity=3).fit_transform(numpy.array(embeddings))\n",
    "    # from sklearn.decomposition import PCA\n",
    "    # umap_result = PCA(n_components=2).fit_transform(numpy.array(embeddings))\n",
    "\n",
    "    for post, umap_result in zip(all_posts, umap_result):\n",
    "        post._x, post._y = umap_result\n",
    "\n",
    "    weirdness_level_embedding = sentence_transformer.encode(\n",
    "        [\"things that are artistic, weird or nerdy\"]\n",
    "    )\n",
    "\n",
    "    for post in all_posts:\n",
    "        post.weirdness = float(util.cos_sim(weirdness_level_embedding, post.embeddings))\n",
    "\n",
    "    max_weirdness = max(post.weirdness for post in all_posts)\n",
    "\n",
    "    for post in all_posts:\n",
    "        post.weirdness /= max_weirdness\n",
    "\n",
    "    for post in all_posts:\n",
    "        post.related_posts = [\n",
    "            RelatedPost(post=similar_post, similarity=post.distance_to(similar_post))\n",
    "            for similar_post in sorted(\n",
    "                all_posts, key=lambda post_to_sort: post_to_sort.distance_to(post)\n",
    "            )\n",
    "            if similar_post != post\n",
    "        ]\n",
    "\n",
    "    return all_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec292e94-0483-4f57-b521-dc7281f63f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content/now.md was recently modified\n",
      "content/how-to-think.md was recently modified\n",
      "content/waiting-room.md was recently modified\n"
     ]
    }
   ],
   "source": [
    "all_posts = get_all_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1d6068-12f1-4e94-a13f-f7aaa7b775c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bookmarks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts[0].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd63b89d-4094-4c15-92d8-a1f11b4e26b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contact'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts[0].related_posts[1].post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0bcde59-08f4-44ad-b319-210149d41e40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style=\"background-color: black\" src=\"./generated/connections.svg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = graphviz.Graph(\n",
    "    comment=\"All Relations\",\n",
    "    graph_attr={\n",
    "        \"bgcolor\": \"transparent\",\n",
    "        \"overlap\": \"false\",\n",
    "        \"outputorder\": \"edgesfirst\",\n",
    "    },\n",
    "    format=\"svg\",\n",
    "    node_attr={\"shape\": \"box\", \"nodesep\": \"0.55\"},\n",
    "    engine=\"neato\",\n",
    ")\n",
    "\n",
    "\n",
    "existing_connections: list[set[Post, Post]] = []\n",
    "ACCENT_COLOR = \"#82AAFF\"\n",
    "UMAP_POSITION_TO_GRAPHVIZ_MULTIPLIER = 0.40\n",
    "\n",
    "\n",
    "def make_node(graph: graphviz.Graph, post: Post, accent_style: bool = False):\n",
    "    if accent_style:\n",
    "        color = ACCENT_COLOR\n",
    "    else:\n",
    "        color = \"#ffffff\"\n",
    "        transparency = f\"{int(255 * post.weirdness):02x}\"\n",
    "        color += transparency\n",
    "\n",
    "    xlabel = \"\"\n",
    "    if post.recently_modified:\n",
    "        xlabel = \"!\"\n",
    "\n",
    "    graph.node(\n",
    "        post.title,\n",
    "        # label=\"< <B>\" + graphviz.nohtml(post.title) + \"</B> >\",\n",
    "        label=\"\\n\".join(textwrap.wrap(post.title, width=16)),\n",
    "        color=color,\n",
    "        fillcolor=\"#263238\",\n",
    "        style=\"filled\",\n",
    "        fontcolor=ACCENT_COLOR if accent_style else \"white\",\n",
    "        penwidth=\"2.0\" if accent_style else \"1.0\",\n",
    "        xlabel=xlabel,\n",
    "        URL=\"/\" + post.path.with_suffix(\"\").name,\n",
    "        pos=f\"{post.x * UMAP_POSITION_TO_GRAPHVIZ_MULTIPLIER},{post.y * UMAP_POSITION_TO_GRAPHVIZ_MULTIPLIER}!\",\n",
    "    )\n",
    "\n",
    "\n",
    "for post in all_posts:\n",
    "    make_node(graph, post)\n",
    "\n",
    "    related_posts = [\n",
    "        similiar_post\n",
    "        for similiar_post in sorted(\n",
    "            all_posts, key=lambda post_to_sort: post_to_sort.distance_to(post)\n",
    "        )\n",
    "        if similiar_post.path != post.path\n",
    "    ]\n",
    "\n",
    "    related_posts_json_path = Path(\"./generated\") / post.path.relative_to(\n",
    "        \"content\"\n",
    "    ).with_suffix(\".json\")\n",
    "    related_posts_json_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(related_posts_json_path, \"w\", encoding=\"utf-8\") as relations_file:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"posts\": [\n",
    "                    {\"title\": related_post.title, \"url\": related_post.link}\n",
    "                    for related_post in related_posts[:2]\n",
    "                ]\n",
    "            },\n",
    "            relations_file,\n",
    "        )\n",
    "\n",
    "    connections_created = 0\n",
    "    for related in related_posts:\n",
    "        if {post, related} not in existing_connections:\n",
    "            graph.edge(\n",
    "                post.title,\n",
    "                related.title,\n",
    "                color=\"white\" if connections_created == 0 else \"gray\",\n",
    "            )\n",
    "            existing_connections.append({post, related})\n",
    "            connections_created += 1\n",
    "\n",
    "        if connections_created > 1:\n",
    "            break\n",
    "# Note: it actually renders to connections.svg\n",
    "graph.render(\"./generated/connections\")\n",
    "display(\n",
    "    HTML('<img style=\"background-color: black\" src=\"./generated/connections.svg\"/>')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e7f6a8-d8f1-41f8-a82e-897677559b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Making node Website experience\n",
      " Making node Contact\n",
      " Making node Registry-based search engine\n",
      " Making node Decentralisation\n",
      " Making node Caddy\n",
      "generated/bookmarks\n",
      " Making node Daily open-source software guide\n",
      " Making node NixOs\n",
      " Making node Caddy\n",
      " Making node Decentralisation\n",
      " Making node Colour scheme\n",
      "generated/alternatives\n",
      " Making node Decentralisation\n",
      " Making node Contact\n",
      " Making node Daily open-source software guide\n",
      " Making node Content creation workflow\n",
      " Making node Software alternatives\n",
      "generated/caddy\n",
      " Making node System configuration\n",
      " Making node Colour scheme\n",
      " Making node Software alternatives\n",
      " Making node About\n",
      " Making node 2024's Devlog\n",
      "generated/nixos\n",
      " Making node 2024's Devlog\n",
      " Making node 2022's Devlog\n",
      " Making node 2023's Devlog\n",
      " Making node NixOs\n",
      " Making node Listening\n",
      "generated/about\n",
      " Making node Registry-based search engine\n",
      " Making node Bookmarks\n",
      " Making node Map\n",
      " Making node Contact\n",
      " Making node Exocortex\n",
      "generated/website-experience\n",
      " Making node Resources on audio & DSP\n",
      " Making node Luthier\n",
      " Making node Custom synth\n",
      " Making node Sounds & Melodies\n",
      " Making node Rust\n",
      "generated/making-music-linux\n",
      " Making node Caddy\n",
      " Making node Daily open-source software guide\n",
      " Making node Content creation workflow\n",
      " Making node Contact\n",
      " Making node Bookmarks\n",
      "generated/decentralisation\n",
      " Making node Registry-based search engine\n",
      " Making node Website experience\n",
      " Making node Exocortex\n",
      " Making node How to think\n",
      " Making node The Waiting room\n",
      "generated/map\n",
      " Making node Caddy\n",
      " Making node 2022's Devlog\n",
      " Making node Decentralisation\n",
      " Making node Bookmarks\n",
      " Making node About\n",
      "generated/contact\n",
      " Making node Resources on audio & DSP\n",
      " Making node Custom synth\n",
      " Making node Custom sequencer\n",
      " Making node Making music on Linux\n",
      " Making node Luthier\n",
      "generated/gpu-synth\n",
      " Making node The Ławka Initiative\n",
      " Making node Excellent Words\n",
      " Making node Cosmic Horror\n",
      " Making node Reading\n",
      " Making node Paintings\n",
      "generated/baczek-in-polish\n",
      " Making node Sounds & Melodies\n",
      " Making node Piano\n",
      " Making node Custom sequencer\n",
      " Making node Resources on audio & DSP\n",
      " Making node Making music on Linux\n",
      "generated/music-transcribing\n",
      " Making node Map\n",
      " Making node Registry-based search engine\n",
      " Making node How to think\n",
      " Making node Website experience\n",
      " Making node The Waiting room\n",
      "generated/exocortex\n",
      " Making node Cosmic Horror\n",
      " Making node The Waiting room\n",
      " Making node Paintings\n",
      " Making node Movies/shows\n",
      " Making node How to think\n",
      "generated/reading\n",
      " Making node Making music on Linux\n",
      " Making node Sounds & Melodies\n",
      " Making node Luthier\n",
      " Making node Piano\n",
      " Making node Resources on audio & DSP\n",
      "generated/rust\n",
      " Making node About\n",
      " Making node NixOs\n",
      " Making node Listening\n",
      " Making node System configuration\n",
      " Making node 2023's Devlog\n",
      "generated/now\n",
      " Making node The Waiting room\n",
      " Making node Reading\n",
      " Making node Map\n",
      " Making node Paintings\n",
      " Making node Exocortex\n",
      "generated/how-to-think\n",
      " Making node Cosmic Horror\n",
      " Making node Reading\n",
      " Making node Travel\n",
      " Making node The Waiting room\n",
      " Making node 2023's Devlog\n",
      "generated/watching\n",
      " Making node Decentralisation\n",
      " Making node Daily open-source software guide\n",
      " Making node Caddy\n",
      " Making node Bookmarks\n",
      " Making node Contact\n",
      "generated/content-creation-workflow\n",
      " Making node Colour scheme\n",
      " Making node NixOs\n",
      " Making node 2024's Devlog\n",
      " Making node Software alternatives\n",
      " Making node About\n",
      "generated/linux\n",
      " Making node 2023's Devlog\n",
      " Making node About\n",
      " Making node Contact\n",
      " Making node Movies/shows\n",
      " Making node Listening\n",
      "generated/2022\n",
      " Making node The word *Bączek*\n",
      " Making node Cosmic Horror\n",
      " Making node Travel\n",
      " Making node Movies/shows\n",
      " Making node Reading\n",
      "generated/lawka\n",
      " Making node Music Transcribing\n",
      " Making node Sounds & Melodies\n",
      " Making node Rust\n",
      " Making node Making music on Linux\n",
      " Making node Resources on audio & DSP\n",
      "generated/piano\n",
      " Making node Decentralisation\n",
      " Making node Software alternatives\n",
      " Making node Caddy\n",
      " Making node Content creation workflow\n",
      " Making node Contact\n",
      "generated/open-source-daily-guide\n",
      " Making node How to think\n",
      " Making node Reading\n",
      " Making node Movies/shows\n",
      " Making node Cosmic Horror\n",
      " Making node Map\n",
      "generated/waiting-room\n",
      " Making node Making music on Linux\n",
      " Making node Resources on audio & DSP\n",
      " Making node GPU Synth\n",
      " Making node Luthier\n",
      " Making node Sounds & Melodies\n",
      "generated/synth-design-idea-dump\n",
      " Making node Paintings\n",
      " Making node The word *Bączek*\n",
      " Making node Reading\n",
      " Making node Cosmic Horror\n",
      " Making node The Ławka Initiative\n",
      "generated/excellent-words\n",
      " Making node Excellent Words\n",
      " Making node Reading\n",
      " Making node How to think\n",
      " Making node Cosmic Horror\n",
      " Making node The Waiting room\n",
      "generated/paintings\n",
      " Making node 2023's Devlog\n",
      " Making node Travel\n",
      " Making node 2024's Devlog\n",
      " Making node About\n",
      " Making node 2022's Devlog\n",
      "generated/listening\n",
      " Making node System configuration\n",
      " Making node NixOs\n",
      " Making node Software alternatives\n",
      " Making node 2024's Devlog\n",
      " Making node Rust\n",
      "generated/theme\n",
      " Making node Reading\n",
      " Making node Movies/shows\n",
      " Making node The Ławka Initiative\n",
      " Making node The Waiting room\n",
      " Making node The word *Bączek*\n",
      "generated/cosmic-horror\n",
      " Making node Making music on Linux\n",
      " Making node GPU Synth\n",
      " Making node Custom synth\n",
      " Making node Custom sequencer\n",
      " Making node Sounds & Melodies\n",
      "generated/dsp\n",
      " Making node Website experience\n",
      " Making node Map\n",
      " Making node Exocortex\n",
      " Making node Bookmarks\n",
      " Making node How to think\n",
      "generated/search-registry-manifesto\n",
      " Making node Resources on audio & DSP\n",
      " Making node GPU Synth\n",
      " Making node Music Transcribing\n",
      " Making node Sounds & Melodies\n",
      " Making node Making music on Linux\n",
      "generated/custom-sequencer-idea-dump\n",
      " Making node Making music on Linux\n",
      " Making node Custom synth\n",
      " Making node Rust\n",
      " Making node Resources on audio & DSP\n",
      " Making node Sounds & Melodies\n",
      "generated/luthier\n",
      " Making node Music Transcribing\n",
      " Making node Piano\n",
      " Making node Making music on Linux\n",
      " Making node Rust\n",
      " Making node Resources on audio & DSP\n",
      "generated/sounds\n",
      " Making node Listening\n",
      " Making node 2023's Devlog\n",
      " Making node Movies/shows\n",
      " Making node The Ławka Initiative\n",
      " Making node Cosmic Horror\n",
      "generated/travel\n",
      " Making node 2022's Devlog\n",
      " Making node Listening\n",
      " Making node About\n",
      " Making node Travel\n",
      " Making node Movies/shows\n",
      "generated/2023\n"
     ]
    }
   ],
   "source": [
    "for current_post in all_posts:\n",
    "    graph = graphviz.Graph(\n",
    "        comment=\"Relations for node\",\n",
    "        graph_attr={\n",
    "            \"bgcolor\": \"transparent\",\n",
    "            \"overlap\": \"false\",\n",
    "            \"outputorder\": \"edgesfirst\",\n",
    "        },\n",
    "        format=\"svg\",\n",
    "        node_attr={\"shape\": \"box\", \"nodesep\": \"0.55\"},\n",
    "        engine=\"neato\",\n",
    "    )\n",
    "\n",
    "    posts_nearby = sorted(all_posts, key=lambda p: p.distance_to(current_post))\n",
    "\n",
    "    nodes_in_graph = {current_post}\n",
    "    make_node(graph, current_post, accent_style=True)\n",
    "\n",
    "    for post in posts_nearby[1:6]:\n",
    "        print(\" Making node\", post.title)\n",
    "        nodes_in_graph.add(post)\n",
    "        make_node(graph, post, accent_style=False)\n",
    "\n",
    "    for connection in existing_connections:\n",
    "        if len(connection & nodes_in_graph) == 2:\n",
    "            node_1 = list(connection)[0]\n",
    "            node_2 = list(connection)[1]\n",
    "\n",
    "            # print(\"Linking\", node_1.title, \"with\", node_2.title)\n",
    "            graph.edge(\n",
    "                node_1.title,\n",
    "                node_2.title,\n",
    "                color=\"white\" if (id(node_1) // 10) % 2 else \"gray\"\n",
    "                # color=\"white\" if target in [ post.post for post in post.related_posts][:1] else \"gray\",\n",
    "            )\n",
    "\n",
    "    related_posts_svg_path = Path(\"./generated\") / current_post.path.relative_to(\n",
    "        \"content\"\n",
    "    ).with_suffix(\"\")\n",
    "    related_posts_svg_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    graph.render(related_posts_svg_path)\n",
    "    print(related_posts_svg_path)\n",
    "    # graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89674a7e-bfa6-4d4c-bbc8-24f4b79380fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': \"2024's Devlog\", 'url': '/now'}, {'title': 'How to think', 'url': '/how-to-think'}, {'title': 'The Waiting room', 'url': '/waiting-room'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "recent_updates = [ { \"title\": post.title, \"url\": post.link } for post in all_posts if post.recently_modified ]\n",
    "\n",
    "with open(\"./generated/recently_updated.json\", \"w\") as recent_updates_file:\n",
    "    print(recent_updates)\n",
    "    json.dump(recent_updates, recent_updates_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0016da1a-5784-41c5-9084-c84974626822",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./generated/build_date.txt\", \"w\") as build_date:\n",
    "    build_date.write(\n",
    "        datetime.strftime(datetime.now(), '%d/%m/%y %H:%M')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5bd719-f77b-4f69-8323-23eee26789d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom feed generated\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from git import Repo\n",
    "\n",
    "ATOM_FEED_HEAD = \"\"\"\n",
    "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
    "\n",
    "<title>Baczek.me Devlog</title>\n",
    "<link href=\"https://baczek.me/\"/>\n",
    "<updated>2003-12-13T18:30:02Z</updated>\n",
    "<author>\n",
    "<name>Mateusz Bączek</name>\n",
    "</author>\n",
    "<id>https://baczek.me/</id>\n",
    "\"\"\"\n",
    "\n",
    "ATOM_FEED_TAIL =\"\"\" \n",
    "</feed>\n",
    "\"\"\"\n",
    "\n",
    "DEVLOG_URL = \"https://baczek.me/now\"\n",
    "\n",
    "def generate_entry(link: str, updated: datetime, commit_hash: str) -> str:\n",
    "    return f\"\"\"\n",
    "      <entry>\n",
    "        <title>{updated.strftime('%d.%m.%Y')} Devlog update</title>\n",
    "        <link href=\"{link}\"/>\n",
    "        <updated>{updated.isoformat()}</updated>\n",
    "        <summary>DevLog available at {link}</summary>\n",
    "        <id>https://baczek.me/now#f{commit_hash}</id>\n",
    "      </entry>\n",
    "  \"\"\"\n",
    "\n",
    "with open(\"./static/atom.xml\", \"w\") as feed_file:\n",
    "    repo = Repo('./')\n",
    "    devlog_changes = list(repo.iter_commits(all=True, paths=\"./content/now.md\"))  # Gets the last 10 commits from all branches.\n",
    "    devlog_changes.reverse()\n",
    "\n",
    "    feed_file.write(ATOM_FEED_HEAD)\n",
    "\n",
    "    for commit in devlog_changes:\n",
    "        feed_file.write(generate_entry(DEVLOG_URL, commit.committed_datetime, commit.hexsha))\n",
    "\n",
    "    feed_file.write(ATOM_FEED_TAIL)\n",
    "\n",
    "print(\"Atom feed generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07308fc2-26ea-493c-9bf5-92a0dd74d1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
